name: convo-ai
hyperparameters:
  model_checkpoint: openai-gpt
  use_pretrained_weights: true
  use_apex_amp: false
  # Loss coefs
  lm_coef: 1.0
  mc_coef: 1.0
  # Training Args
  global_batch_size: 32
  learning_rate: 6.25e-5
  adam_epsilon: 1e-8
  weight_decay: 0
  lr_scheduler_type: linear
  num_warmup_steps: 0
  num_training_steps: 12322
  max_grad_norm: 1.0
data:
  dataset_path: ""
  dataset_cache: /root/.cache/
  num_candidates: 2
  max_history: 2
  personality_permutations: 1
optimizations:
  aggregation_frequency: 8
  tensor_fusion_cycle_time: 1
# Number of records per epoch differs based on max_seq_length.
records_per_epoch: 131438
min_validation_period:
  batches: 1000
searcher:
  name: single
  metric: ppl
  max_length:
    epochs: 3
  smaller_is_better: true
environment:
  image: determinedai/model-hub-transformers:0.16.0
resources:
  slots_per_trial: 8
# We add a bind_mount here so that cached data, tokenized data, and models will be saved to the
# host_path on the agent instance disk for reuse if the same experiment is run on this instance.
bind_mounts:
  - host_path: /tmp
    container_path: /root/.cache
entrypoint: model_def:ConvoAITrial
