# Deformable DETR: Deformable Transformers for End-to-end Object Detection  (Zhu et al. 2021)
This example implements the Deformable DETR (DDETR) model introduced by Zhu et al. (2021) in their [recent paper] accepted at ICLR 2021 (https://openreview.net/forum?id=gZ9hCDWe6ke).
DDETR drastically improves the convergence speed of DETR with multi-scale features and sparse spatial sampling with deformable attention.  

This implementation largely uses the original implementation provided in [this repo](https://github.com/fundamentalvision/Deformable-DETR).  With this Determined implementation, you can easily run DDETR with distributed training and hyperparameter search by modifying a few flags in the [experiment config](distributed_gcs.yaml).  Note that the panoptic segmentation task is not supported in this example.

## Files
This example is structure as follows:
* [model_def.py](model_def.py): initializes the data, optimizer, and model and specifies the training and evaluation steps.
* [model.py](model.py): modifies the original [SetCriterion function](https://github.com/fundamentalvision/Deformable-DETR/blob/main/models/deformable_detr.py#L198) to use horovod allreduce to sync number of bounding boxes.
* [data.py](data.py): creates a CocoDetection dataset to work with Google Cloud Storage. 

### Configuration Files
* [distributed_gcs.yaml](distributed_gcs.yaml): distributed training experiment to run with COCO dataset on Google Cloud Storage.
* [distributed_hdd.yaml](distributed_hdd.yaml): distributed training experiment to run with COCO dataset by downloading the data to disk.
* [const_fake.yaml](const_fake.yaml): single-GPU experiment to run with fake data.

## Data
This example requires the COCO 2017 Object Detection dataset.  There are three backends that you can select for accessing the data (see [data.py](data.py)): gcs, local, and fake.  The gcs backend will download images from a Google Cloud Storage bucket, local will download the COCO dataset directly from source to the harddrive and read images from disk, and fake will use a fake image without requiring COCO to be available anywhere.  Experiment config files are provided for each of the access patterns. 

## To Run
If you have the COCO 2017 dataset available in a Google Cloud Storage bucket, you can use [distributed_gcs.yaml](distributed_gcs.yaml) and change the `data_dir` field to your bucket name.  If you want to download the COCO dataset to disk, you can use [distributed_hdd.yaml](distributed_hdd.yaml) and change the `data_dir` field to the data directory.  Note that using a path on the bind mounted path will allow data to persist on the agent even after the container terminates.  Finally, you also have the option of running this example with fake data using the [const_fake.yaml](const_fake.yaml) config.  Submit the experiment to your Determined cluster by running
```
det experiment create <distributed_gcs.yaml> .
```
from the command line.

## Results
The training and validation curves generated by this experiment are shown below.  They closely match the reported result of 43.8 after 50 epochs on COCO from the paper (see Table 1) using [the base configuration in the original repo](https://github.com/fundamentalvision/Deformable-DETR/blob/main/configs/r50_deformable_detr.sh).

![train_curves](imgs/train_curves.png)
![val_curves](imgs/val_curves.png)
